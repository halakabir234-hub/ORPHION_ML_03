# -*- coding: utf-8 -*-
"""Task_03_Markov_Chain_Text_Generator.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jgiMyhXBkTnuTfnm9LRuX3tm8oDkadcM

# Task 03 â€“ Markov Chain Text Generator

This project implements a statistical text generator using **Markov Chains**.
The model predicts the next word based on the previous word(s), demonstrating
a foundational concept behind modern Generative AI systems.

**Skills Used:** Probability, N-grams, Python  
**Objective:** Generate pseudo-random sentences that mimic a source text.
"""

import random
import re

text = """
Artificial intelligence is transforming the world.
Artificial intelligence is used in healthcare.
Artificial intelligence helps in education and automation.
The future of artificial intelligence is very promising.
"""

# Convert text to lowercase and remove special characters
text = text.lower()
text = re.sub(r'[^a-z\s]', '', text)

words = text.split()
print(words)

markov_chain = {}

for i in range(len(words) - 1):
    current_word = words[i]
    next_word = words[i + 1]

    if current_word not in markov_chain:
        markov_chain[current_word] = []

    markov_chain[current_word].append(next_word)

# View part of the Markov chain
markov_chain

def generate_text(chain, start_word, length=20):
    current_word = start_word
    result = [current_word]

    for _ in range(length - 1):
        if current_word not in chain:
            break
        current_word = random.choice(chain[current_word])
        result.append(current_word)

    return " ".join(result)

output = generate_text(markov_chain, start_word="artificial", length=25)
print(output)

"""## Conclusion

This project demonstrates how Markov Chains use probability and word transitions
to generate text. While simple compared to deep learning models, this approach
represents the foundation of modern text generation systems such as GPT.

The generated sentences mimic the structure and style of the source text,
producing pseudo-random yet meaningful outputs.

"""